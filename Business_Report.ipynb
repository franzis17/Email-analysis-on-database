{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1p733R7aik3ZStdCE-yfRGK624m0JrULl",
      "authorship_tag": "ABX9TyP4vrNya7T1/qp09V8scLd2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/franzis17/EnronEmailAnalysis/blob/main/Business_Report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Packages\n"
      ],
      "metadata": {
        "id": "Rs9DnFynSl4O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialise all packages needed in the program\n",
        "\n",
        "Packages used:\n",
        "* calendar --> \n",
        "* matplotlib --> for visualisation purposes. Plot the data in to some kind of a chart.\n",
        "* pandas --> for efficiently sorting different kinds of data (i.e. sorting messages data in a monthly order)\n",
        "* sqlite3 --> for extracting data in the database and perform 3 different kinds of analysis on the data\n",
        "\n"
      ],
      "metadata": {
        "id": "qHThh5d3St-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import calendar\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import re  # regular expression\n",
        "import sqlite3\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# Generate Stopwords\n",
        "from google.colab import output\n",
        "!curl -Ol https://raw.githubusercontent.com/michael-borck/isys2001-worksheets/main/stopwords.py\n",
        "output.clear()\n",
        "print(\"Required packages installed\")"
      ],
      "metadata": {
        "id": "KGFqMjCaS1Vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to the database"
      ],
      "metadata": {
        "id": "0wkqGhm5S064"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiH5U7szSg37"
      },
      "outputs": [],
      "source": [
        "# Connect to the database using 'sqlite3'\n",
        "conn = sqlite3.connect('/content/drive/MyDrive/a-quick_uploads/enron.db')\n",
        "\n",
        "# Create a cursor to navigate each rows in the database and query any specific data from the dataset\n",
        "cur = conn.cursor()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <u>**Analysis 1.**</u> Email Traffic Over Time\n",
        "\n",
        "Aim: Analyze the volume of emails sent over time by counting the number of messages of each employees sent per month.\n",
        "\n",
        "## **Problem:**\n",
        "\n",
        "* Must count the total number of messages of all employees they are sending per month.\n",
        "\n",
        "## **Inputs:**\n",
        "\n",
        "* List of messages\n",
        "\n",
        "## **Outputs:**\n",
        "\n",
        "* A line chart that shows the number of emails per month. (x = month, y = number of emails(messages))\n",
        "\n",
        "## **Algorithm:**\n",
        "  1. Create a dataframe based on an SQL statement that obtains all messages from the database table \"message\".\n",
        "  2. Using the \"message\" dataframe, use the total amount of messages of the dataframe to sort the data monthly.\n",
        "  3. Using the monthly-sorted messages data, create a line chart that shows the total amount of messages per month.\n",
        "\n",
        "* **Important**: Must close the connection to the SQLite Database when done with the database.\n",
        "\n",
        "## **Python Implementation:**"
      ],
      "metadata": {
        "id": "1yk1TLA0TAvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Note:\n",
        "> Lines 12 to 29 were generated by ChatGPT. More info on reference list [ChatGPT-1]\n",
        "'''\n",
        "\n",
        "# Query database for all messages and to be put on a dataframe\n",
        "sql='''\n",
        "SELECT * FROM message\n",
        "'''\n",
        "messages_df = pd.read_sql(sql, conn)\n",
        "\n",
        "# Make a new month table to group each messages by month\n",
        "messages_df['date'] = pd.to_datetime(messages_df['date'])\n",
        "messages_df['month'] = messages_df['date'].dt.month\n",
        "\n",
        "# Apply month names instead of the month numbers\n",
        "messages_df['month'] = messages_df['month'].apply(lambda x: calendar.month_name[x])\n",
        "# Set month as a categorical column with desired order (Order the month chronologically)\n",
        "month_order = [calendar.month_name[i] for i in range(1, 13)]\n",
        "messages_df['month'] = pd.Categorical(messages_df['month'], categories=month_order, ordered=True)\n",
        "\n",
        "monthly_counts = messages_df.groupby('month').size()\n",
        "monthly_counts.plot(kind='line', figsize=(10, 6))\n",
        "\n",
        "# Plot the total amount of messages sent per month\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Number of messages')\n",
        "plt.title('Total Number of Messages per Month in the year 2000')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q7h1SVFyTmV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <u>**Analysis 2.**</u> Top Senders and Receivers\n",
        "Aim: Identify the most frequent email senders and recipients by aggregating(collecting) the data in the 'Message' and 'RecepientInfo' tables."
      ],
      "metadata": {
        "id": "MTFaWZv6UNHg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vHfmdm0jUuUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <u>**Analysis 3.**</u> Subject Keyword Analysis\n",
        "Aim: Extract keywords from email subjects in the 'Message' table and analyze the frequency of words used to understand common topics of discussion.\n",
        "\n",
        "## **Problem:**\n",
        "\n",
        "* Must understand the common topics of discussion from the dataset of 'Message' table to see if it is related to any potential fraudulent activities.\n",
        "\n",
        "## **Inputs:**\n",
        "\n",
        "* List of words from the subject section of all email email messages. (database table located in message.subject)\n",
        "\n",
        "## **Outputs:**\n",
        "\n",
        "* WordCloud that shows the most common words used in the subject section of the email with. (Frequency of words depends on the size, i.e. large-sized words are most frequently used and smaller-sized are less frequent.)\n",
        "\n",
        "## **Algorithm:**\n",
        "  1. Extract all dataset of 'Message' table.\n",
        "  2. Clean the 'subject' contents of the message dataset to only contain absolute words (words must not contain any symbols/numbers)\n",
        "  3. Generate list of stop words called \"ENGLISH_STOP_WORDS\" from Stopwords.py, which is a list of words that do not provide much meaning to the analysis.\n",
        "  4. Create a WordCloud using the \"Cleaned-subject\" list of words.\n",
        "\n",
        "## **Python Implementation:**"
      ],
      "metadata": {
        "id": "vmXbjkIKUuj9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before running: Must run the Analysis 1 first to get the dataframe of messages \"messages_df\""
      ],
      "metadata": {
        "id": "6FEbFG-5VWDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stopwords import ENGLISH_STOP_WORDS\n",
        "\n",
        "# [Ref-2]\n",
        "def clean(text):\n",
        "    ''' Uses regular expresison to extract english letter and digits from the supplied text. '''\n",
        "    regExp = \"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\"\n",
        "    return ' '.join(re.sub(regExp, \" \", text).split())\n",
        "\n",
        "\n",
        "# no need to extract messages from the database assuming it has been extracted from Analysis 1\n",
        "\n",
        "# Create a new column as a placeholder for the clean subject keywords\n",
        "messages_df['Clean Subject'] = messages_df['subject'].apply(clean)\n",
        "\n",
        "# Add additional words to stopwords that do not have much meaning\n",
        "additional_stop_words = {'New', 'Meeting', 'Update', 'Enron', 'Market', 'Power', 'Caiso', 'Notice', 'Hour', 'HourAhead', 'California', 'FW', 'Date', 'Fwd', 'Letter', 'Deal'}\n",
        "ENGLISH_STOP_WORDS.update(additional_stop_words)\n",
        "\n",
        "# Create and Display the wordcloud\n",
        "subjects = ' '.join(messages_df['Clean Subject'])\n",
        "wordcloud = WordCloud(width=680, height=480, margin=0, stopwords=ENGLISH_STOP_WORDS).generate(subjects)\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.margins(x=0, y=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aOVjT8YRVVe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Discussion:**\n",
        "\n",
        "Below are some keywords that implies something:\n",
        "\n",
        "* \"Codesite\":\n",
        "  * Based from analysing the message body of all subjects with the keyword \"Codesite\", it looks like the company had some for of system that checks for any variances to "
      ],
      "metadata": {
        "id": "XYrslQh4aCvM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Close the connection to the database\n",
        "**Note:** Use when done with the database"
      ],
      "metadata": {
        "id": "H6tQlq1FXHrh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conn.close()"
      ],
      "metadata": {
        "id": "T5MUE-2jXIlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reference List\n",
        "\n",
        "* [1] https://pandas.pydata.org/docs/user_guide/10min.html#plotting\n",
        "* [2] Clean function obtained from WK-9 tutorial and is used to remove symbols and numbers from words.\n",
        "\n",
        "**ChatGPT**\n",
        "* [1]\n",
        "  * Purpose: To plot the frequency of messages per month to a line chart\n",
        "  * Prompt: how can I use pandas package in python to plot the frequency of messages per month in a year, given the messages data are in a dataframe."
      ],
      "metadata": {
        "id": "6s1mKP3YWlbv"
      }
    }
  ]
}